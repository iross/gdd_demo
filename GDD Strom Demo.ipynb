{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoDeepDive Application Demo\n",
    "\n",
    "## Wrangling text data from GeoDeepDive\n",
    "\n",
    "The Python script `find_target.py` is a simplified component of the data-mining application utilized in [Peters, Husson and Wilcots (in press, Geology)](https://github.com/UW-Macrostrat/stromatolites_demo), which utilizes the [GeoDeepDive](https://geodeepdive.org) digital library to constrain the spatio-temporal distribution of stromatolite fossils across Earth history. This script searches for user-defined word(s) or phrases in 5 provided USGS Technical Reports that have been processed and annotated by GeoDeepDive. The output is a list of `document-sentence` tuples that uniquely describe the location of the specified word(s) within the GeoDeepDive library, along with any adjectives that are used to describe those word(s). It serves as a demonstration of what data derived from GeoDeepDive looks like, and how it can be manipulated in simple ways to gain knowledge about the published literature.\n",
    "\n",
    "## Input description\n",
    "\n",
    "Input for `find_target.py` are two text files: `input/sentences_nlp352` and `var/target_variables.py`. The `sentences_nlp352` file comes from the GeoDeepDive library, and is a TSV file containing 5 technical reports from the United States Geological Survey that have been parsed using [Stanford Natural Language Processing](http://nlp.stanford.edu/) (version 3.5.2). More detailed information about the sentences table data structure can be found [here](https://github.com/jonhusson/gdd_demo/tree/master/input). You can also view a reference list describing the five included reports [here](https://github.com/jonhusson/gdd_demo/blob/master/input/references.pdf); it is also in the downloaded input folder as `references.pdf`.\n",
    "\n",
    "The `var/target_variables.py` file can (and should!) be altered by the user, and principally consists of Python list of strings called `target_names`. Each object in the list is searched for within the set of five documents, using Python's regular expressions module. It also includes a list of \"bad\" words, which should not be considered matches. For example, the default values provided are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['stromatol', r'\\b' + 'Gamuza Formation' + r'\\b']\n",
    "bad_words = ['non-stromatolitic','nonstromatolitic','non-stromatolite']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meaning that words containing the string fragment `stromatol` will be returned (i.e., stromatolite, stromatolitic), as well as the phrase `Gamuza Formation`, provided the latter is bound by non-alphanumeric characters (e.g., `TheNotGamuza Formation` will not be returned). Words such as non-stromatolitic, which would be considered matches based on the regex on the target_name, are vetoed by its inclusion in the bad_words list. These lists can be altered to anything you like!\n",
    "\n",
    "## Running the script\n",
    "\n",
    "The find_target function can simply be imported into this notebook (or a similar script) and run from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_target import find_target\n",
    "hits = find_target(target_names, bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or it can be run from your terminal, where it will default to the target_names and bad_words specified in `var/target_variables.py`\n",
    "\n",
    "\n",
    "## Output description\n",
    "\n",
    "The result of running `find_target.py` will be written to `output/output.tsv` as tab-delimited text file. Each row consists of a discovery of one of the strings specified in `var/target_variables.py`.  The columns are described below:\n",
    "\n",
    "Column | Description \n",
    "-------|--------\n",
    "docid| identifier for the relevant document from the GeoDeepDive database, with metadata for it available through the GeoDeepDive API (i.e., [558dcf01e13823109f3edf8e](https://geodeepdive.org/api/articles?id=558dcf01e13823109f3edf8e))\n",
    "sentid| identifier for sentence within the specified document where the `target` was extracted\n",
    "target| discovered word or phrase (e.g., stromatolite, stromatolites, stromatolitic).\n",
    "start\\_idx| Pythonic index for start of discovered `target` (e.g., `0` would mean first word in that sentence).\n",
    "end\\_idx| Pythonic index for end of discovered `target`\n",
    "adjective| words determined by [NLP](http://nlp.stanford.edu/) to be an adjective describing `target` (e.g., `Riphean, domal stromatolites`)\n",
    "sentence| full sentence in which `target` was discovered\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'adjectives': [],\n",
       "  'docid': '558dcf01e13823109f3edf8e',\n",
       "  'end_idx': 8,\n",
       "  'sentence': '__________________________ 10 Pitiquito Quartzite ____________________________ 11 Gamuza Formation - ___________________________ 12 Papalote Formation ___________________________ 14 Tecolote Quartzite ____________________________ 15 La Cienega Formation _________________________ 15 Puerto Blanco Formation - ______________________ 15 Proveedora Quartzite __________________________ 16 Page Physical stratigraphy of upper Proterozoic and Cambrian rocks Continued ______________________ 17 Buelna Formation ____________________________ 17 Cerro Prieto Formation ________________________ 17 Arrojos Formation ____________________________ 17 Tren Formation ______________________________ 17 Biostratigraphy _ _________________________________ 17 Paleocurrent studies ______________________________ 22 Regional correlations _____________________________ 25 Southern Great Basin _________________________ 25 San Bernardino Mountains _____________________ 28 Sierra Agua Verde ____________________________ 29 Tectonic and paleogeographic setting ________________ 30 Model A _____________ .',\n",
       "  'sentid': '19',\n",
       "  'start_idx': 6,\n",
       "  'target_word': 'Gamuza Formation'},\n",
       " {'adjectives': ['conical'],\n",
       "  'docid': '558dcf01e13823109f3edf8e',\n",
       "  'end_idx': 4,\n",
       "  'sentence': 'Photographs of conical stromatolites in the upper unit of the Gamuza Formation in the Cerro Rajon area __ 9 .',\n",
       "  'sentid': '30',\n",
       "  'start_idx': 3,\n",
       "  'target_word': 'stromatolites'},\n",
       " {'adjectives': [],\n",
       "  'docid': '558dcf01e13823109f3edf8e',\n",
       "  'end_idx': 12,\n",
       "  'sentence': 'Photographs of conical stromatolites in the upper unit of the Gamuza Formation in the Cerro Rajon area __ 9 .',\n",
       "  'sentid': '30',\n",
       "  'start_idx': 10,\n",
       "  'target_word': 'Gamuza Formation'},\n",
       " {'adjectives': ['conical'],\n",
       "  'docid': '558dcf01e13823109f3edf8e',\n",
       "  'end_idx': 20,\n",
       "  'sentence': 'The sequence contains a wide assortment of fossils that include algallike filaments , possible trace fossils , and conical stromatolites -LRB- Conophyton and related forms -RRB- in the upper Proterozoic rocks ; a primitive shelly fauna in the lowermost Cambrian rocks ; and archaeocyathids , trilobites , Salterella , Hyolithes , Gimanella , gastropods , and brachiopods in the overlying Cambrian rocks .',\n",
       "  'sentid': '45',\n",
       "  'start_idx': 19,\n",
       "  'target_word': 'stromatolites'},\n",
       " {'adjectives': [],\n",
       "  'docid': '558dcf01e13823109f3edf8e',\n",
       "  'end_idx': 16,\n",
       "  'sentence': 'Arellano -LRB- 1946 -RRB- and Cooper and Arellano -LRB- 1946 -RRB- also briefly described the stromatolite-bearing Precambrian rocks in the Caborca region .',\n",
       "  'sentid': '74',\n",
       "  'start_idx': 15,\n",
       "  'target_word': 'stromatolite-bearing'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(hits)\n",
    "hits[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Using the provided Python script and some coding (in any language) of your own:\n",
    "\n",
    "1. What adjectives are used to describe stromatolites?\n",
    "\n",
    "2. Create a list of `document-sentence` tuples for sentences in this test set that contain BOTH `sandstone` and `limestone,` two commonly studied rock types.\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "I recently added a simple script that seeks to determine the start of the \"References\" list in a given GDD document. This information may be helpful, because one may be interested in discarding phrase matches that happen within the reference list or bibliography, focusing only on the main body of the document. To run this extractor, simply type:\n",
    "\n",
    "```\n",
    "python find_refs.py\n",
    "```\n",
    "\n",
    "The output is written to `output/ref_start.tsv`, and consists of `docid-sentid` tuples. For example, for docid `55adf5cde13823763a830891`, the associated sentid is `2783`. This means that for sentences with sentids less than 2783 are the main body of the text (for that particular document), and sentences with sentids greater than or equal to 2783 are determined to be part of the reference list.\n",
    "\n",
    "## find_documents.py\n",
    "In addition to the find_target script, there is also a find_documents script within the repository. This script takes the same input (`var/target_variables.py`) and dumps a list of the GeoDeepDive document IDs which include a term that matches, along with a dump of how many times each target variable occurs in each document (`output/docs_terms.txt`) and the text content of each match (`output/matching_documents.txt`). Additional logic can be applied in this script -- if a list of lists is supplied in `var/target_variables.py`, at least one term from each list is required in order for the document to be considered a match For example, ` target_names = [['a'], ['b', 'c']]` will only consider a document to be a match if it includes 'a' and either 'b' or 'c'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55b6cd71e13823bd29ba7d93\tstromatol\t32\n",
      "\n",
      "55b6cd71e13823bd29ba7d93\tStromatol\t1\n",
      "\n",
      "558dcf01e13823109f3edf8e\tGamuza Formation\t28\n",
      "\n",
      "558dcf01e13823109f3edf8e\tGAMUZA FORMATION\t3\n",
      "\n",
      "558dcf01e13823109f3edf8e\tstromatol\t53\n",
      "\n",
      "558dcf01e13823109f3edf8e\tStromatol\t2\n",
      "\n",
      "55adf8dee13823763a8308a7\tstromatol\t257\n",
      "\n",
      "55a68e92e13823757cc6fa6d\tSTROMATOL\t2\n",
      "\n",
      "55a68e92e13823757cc6fa6d\tstromatol\t32\n",
      "\n",
      "55a68e92e13823757cc6fa6d\tStromatol\t7\n",
      "\n",
      "55adf5cde13823763a830891\tstromatol\t40\n",
      "\n",
      "55adf5cde13823763a830891\tStromatol\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from find_documents import find_documents\n",
    "find_documents()\n",
    "with open(\"output/docs_terms.txt\") as fin:\n",
    "    for line in fin:\n",
    "        print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
